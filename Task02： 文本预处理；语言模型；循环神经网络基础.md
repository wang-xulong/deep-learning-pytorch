# Task02： 文本预处理；语言模型；循环神经网络基础

# 文本预处理

## 1 基本步骤

1. 读入文本
2. 分词
3. 建立字典，将每个词映射到一个唯一的索引（index）
4. 将文本从词的序列转换为索引的序列，方便输入模型



# 语言模型

## 1 基本概念

一段自然语言文本可以看作是一个离散时间序列，给定一个长度为𝑇T的词的序列𝑤1,𝑤2,…,𝑤𝑇w1,w2,…,wT，语言模型的目标就是评估该序列是否合理，即计算该序列的概率：

𝑃(𝑤1,𝑤2,…,𝑤𝑇).

## 2 n元语法

序列长度增加，计算和存储多个词共同出现的概率的复杂度会呈指数级增加。𝑛n元语法通过马尔可夫假设简化模型，马尔科夫假设是指一个词的出现只与前面𝑛n个词相关，即𝑛n阶马尔可夫链



缺点：

1)稀疏

2)参数空间大

## 3 采样方式

1. 随机采样
2. 相邻采样





# RNN基础

## 1 特点

非刚性地记忆所有固定长度的序列，而是通过隐藏状态来存储之前时间步的信息。首先我们回忆一下前面介绍过的多层感知机，然后描述如何添加隐藏状态来将它变成循环神经网络。



## 2基本单元的结构图

![img](https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter06/6.2_rnn.svg)



## 3总结

- 使用循环计算的网络即循环神经网络。
- 循环神经网络的隐藏状态可以捕捉截至当前时间步的序列的历史信息。
- 循环神经网络模型参数的数量不随时间步的增加而增长。
- 可以基于字符级循环神经网络来创建语言模型。

